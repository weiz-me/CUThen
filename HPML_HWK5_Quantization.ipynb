{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiz-me/CUThen/blob/main/HPML_HWK5_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTvIwDlYvBzC"
      },
      "source": [
        "# Initial Setup\n",
        "\n",
        "Before beginning the assignment, we import the CIFAR dataset, and train a simple convolutional neural network (CNN) to classify it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiiMcdNJI--"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG3WW1Owq1Fh"
      },
      "source": [
        "**Reminder:** set the runtime type to \"GPU\", or your code will run much more slowly on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3RF5VmcoUMG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCaMDWYArEXO"
      },
      "source": [
        "Load training and test data from the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5UuOjjrnogR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9314679b-058c-426d-9405-085062e0c6cb"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 25747647.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l62CkyIwtSOv"
      },
      "source": [
        "Define a simple CNN that classifies CIFAR images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL3F-7Rntog"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nijieuxptag6"
      },
      "source": [
        "Train this CNN on the training dataset (this may take a few moments)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += images.shape[0]\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "\n",
        "    return 100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HixhBHaqtmZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfa62c5-4750-4590-edcc-0a499fe127b0"
      },
      "source": [
        "train(net, trainloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.191\n",
            "[1,  4000] loss: 1.862\n",
            "[1,  6000] loss: 1.690\n",
            "[1,  8000] loss: 1.617\n",
            "[1, 10000] loss: 1.555\n",
            "[1, 12000] loss: 1.507\n",
            "[2,  2000] loss: 1.464\n",
            "[2,  4000] loss: 1.414\n",
            "[2,  6000] loss: 1.376\n",
            "[2,  8000] loss: 1.352\n",
            "[2, 10000] loss: 1.328\n",
            "[2, 12000] loss: 1.336\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJggxnCVuRxU"
      },
      "source": [
        "Now that the CNN has been trained, let's test it on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27_n-djuEdz",
        "outputId": "75f39a28-e134-432a-d341-83aeb75505c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = test(net, testloader)\n",
        "print('Accuracy of the network on the test images: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 52.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWbC5YWT-MU"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# A convenience function which we use to copy CNNs\n",
        "def copy_model(model: nn.Module) -> nn.Module:\n",
        "    result = deepcopy(model)\n",
        "\n",
        "    # Copy over the extra metadata we've collected which copy.deepcopy doesn't capture\n",
        "    if hasattr(model, 'input_activations'):\n",
        "        result.input_activations = deepcopy(model.input_activations)\n",
        "\n",
        "    for result_layer, original_layer in zip(result.children(), model.children()):\n",
        "        if isinstance(result_layer, nn.Conv2d) or isinstance(result_layer, nn.Linear):\n",
        "            if hasattr(original_layer.weight, 'scale'):\n",
        "                result_layer.weight.scale = deepcopy(original_layer.weight.scale)\n",
        "            if hasattr(original_layer, 'activations'):\n",
        "                result_layer.activations = deepcopy(original_layer.activations)\n",
        "            if hasattr(original_layer, 'output_scale'):\n",
        "                result_layer.output_scale = deepcopy(original_layer.output_scale)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQZoEjBSveV8"
      },
      "source": [
        "# Question 1: Visualize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qKRX7ply7I2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2h7zJ8m3GAF"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of weights\n",
        "\n",
        "# You can get a flattened vector of the weights of fc1 like this:\n",
        "#   fc1_weights = net.fc1.weight.data.cpu().view(-1)\n",
        "# Try plotting a histogram of fc1_weights (and the weights of all the other layers as well)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKjshaHD11m"
      },
      "source": [
        "# Question 2: Quantize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNk1fXuPGjB"
      },
      "source": [
        "net_q2 = copy_model(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIBrqSFrVi5x"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def quantized_weights(weights: torch.Tensor) -> Tuple[torch.Tensor, float]:\n",
        "    '''\n",
        "    Quantize the weights so that all values are integers between -128 and 127.\n",
        "    You may want to use the total range, 3-sigma range, or some other range when\n",
        "    deciding just what factors to scale the float32 values by.\n",
        "\n",
        "    Parameters:\n",
        "    weights (Tensor): The unquantized weights\n",
        "\n",
        "    Returns:\n",
        "    (Tensor, float): A tuple with the following elements:\n",
        "                        * The weights in quantized form, where every value is an integer between -128 and 127.\n",
        "                          The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "                        * The scaling factor that your weights were multiplied by.\n",
        "                          This value does not need to be an 8-bit integer.\n",
        "    '''\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    scale = 2.5\n",
        "    result = (weights * scale).round()\n",
        "    return torch.clamp(result, min=-128, max=127), scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOwTnXxU1nb"
      },
      "source": [
        "def quantize_layer_weights(model: nn.Module):\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            q_layer_data, scale = quantized_weights(layer.weight.data)\n",
        "            q_layer_data = q_layer_data.to(device)\n",
        "\n",
        "            layer.weight.data = q_layer_data\n",
        "            layer.weight.scale = scale\n",
        "\n",
        "            if (q_layer_data < -128).any() or (q_layer_data > 127).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include values out of bounds for an 8-bit signed integer\".format(layer.__class__.__name__))\n",
        "            if (q_layer_data != q_layer_data.round()).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include non-integer values\".format(layer.__class__.__name__))\n",
        "\n",
        "quantize_layer_weights(net_q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3HqeBKVoYR"
      },
      "source": [
        "score = test(net_q2, testloader)\n",
        "print('Accuracy of the network after quantizing all weights: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg7bfTF1bBVe"
      },
      "source": [
        "# Question 3: Visualize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP587b0QYxe9"
      },
      "source": [
        "def register_activation_profiling_hooks(model: Net):\n",
        "    model.input_activations = np.empty(0)\n",
        "    model.conv1.activations = np.empty(0)\n",
        "    model.conv2.activations = np.empty(0)\n",
        "    model.fc1.activations = np.empty(0)\n",
        "    model.fc2.activations = np.empty(0)\n",
        "    model.fc3.activations = np.empty(0)\n",
        "\n",
        "    model.profile_activations = True\n",
        "\n",
        "    def conv1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.input_activations = np.append(model.input_activations, x[0].cpu().view(-1))\n",
        "    model.conv1.register_forward_hook(conv1_activations_hook)\n",
        "\n",
        "    def conv2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv1.activations = np.append(model.conv1.activations, x[0].cpu().view(-1))\n",
        "    model.conv2.register_forward_hook(conv2_activations_hook)\n",
        "\n",
        "    def fc1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv2.activations = np.append(model.conv2.activations, x[0].cpu().view(-1))\n",
        "    model.fc1.register_forward_hook(fc1_activations_hook)\n",
        "\n",
        "    def fc2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.fc1.activations = np.append(model.fc1.activations, x[0].cpu().view(-1))\n",
        "    model.fc2.register_forward_hook(fc2_activations_hook)\n",
        "\n",
        "    def fc3_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.fc2.activations = np.append(model.fc2.activations, x[0].cpu().view(-1))\n",
        "            model.fc3.activations = np.append(model.fc3.activations, y[0].cpu().view(-1))\n",
        "    model.fc3.register_forward_hook(fc3_activations_hook)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvPCIoabLC7"
      },
      "source": [
        "net_q3 = copy_model(net)\n",
        "register_activation_profiling_hooks(net_q3)\n",
        "\n",
        "# Run through the training dataset again while profiling the input and output activations this time\n",
        "# We don't actually have to perform gradient descent for this, so we can use the \"test\" function\n",
        "test(net_q3, trainloader, max_samples=400)\n",
        "net_q3.profile_activations = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1HnYsuAMoxP"
      },
      "source": [
        "input_activations = net_q3.input_activations\n",
        "conv1_output_activations = net_q3.conv1.activations\n",
        "conv2_output_activations = net_q3.conv2.activations\n",
        "fc1_output_activations = net_q3.fc1.activations\n",
        "fc2_output_activations = net_q3.fc2.activations\n",
        "fc3_output_activations = net_q3.fc3.activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEo8VK46bwjn"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of activations\n",
        "\n",
        "# Plot histograms of the following variables, and calculate their ranges and 3-sigma ranges:\n",
        "#   input_activations\n",
        "#   conv1_output_activations\n",
        "#   conv2_output_activations\n",
        "#   fc1_output_activations\n",
        "#   fc2_output_activations\n",
        "#   fc3_output_activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haiPVx4ibEra"
      },
      "source": [
        "# Question 4: Quantize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLjSp7hsXofq"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class NetQuantized(nn.Module):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantized, self).__init__()\n",
        "\n",
        "        net_init = copy_model(net_with_weights_quantized)\n",
        "\n",
        "        self.conv1 = net_init.conv1\n",
        "        self.pool = net_init.pool\n",
        "        self.conv2 = net_init.conv2\n",
        "        self.fc1 = net_init.fc1\n",
        "        self.fc2 = net_init.fc2\n",
        "        self.fc3 = net_init.fc3\n",
        "\n",
        "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
        "            def pre_hook(l, x):\n",
        "                x = x[0]\n",
        "                if (x < -128).any() or (x > 127).any():\n",
        "                    raise Exception(\"Input to {} layer is out of bounds for an 8-bit signed integer\".format(l.__class__.__name__))\n",
        "                if (x != x.round()).any():\n",
        "                    raise Exception(\"Input to {} layer has non-integer values\".format(l.__class__.__name__))\n",
        "\n",
        "            layer.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "        # Calculate the scaling factor for the initial input to the CNN\n",
        "        self.input_activations = net_with_weights_quantized.input_activations\n",
        "        self.input_scale = NetQuantized.quantize_initial_input(self.input_activations)\n",
        "\n",
        "        # Calculate the output scaling factors for all the layers of the CNN\n",
        "        preceding_layer_scales = []\n",
        "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
        "            layer.output_scale = NetQuantized.quantize_activations(layer.activations, layer.weight.scale, self.input_scale, preceding_layer_scales)\n",
        "            preceding_layer_scales.append((layer.weight.scale, layer.output_scale))\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_initial_input(pixels: np.ndarray) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor for the images that are input to the first layer of the CNN.\n",
        "\n",
        "        Parameters:\n",
        "        pixels (ndarray): The values of all the pixels which were part of the input image during training\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the input should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return 1.0\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_activations(activations: np.ndarray, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor to multiply the output of a layer by.\n",
        "\n",
        "        Parameters:\n",
        "        activations (ndarray): The values of all the pixels which have been output by this layer during training\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied as part of the \"quantize_weights\" function you wrote earlier\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the layer output should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return 1.0\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # You can access the output activation scales like this:\n",
        "        #   fc1_output_scale = self.fc1.output_scale\n",
        "\n",
        "        # To make sure that the outputs of each layer are integers between -128 and 127, you may need to use the following functions:\n",
        "        #   * torch.Tensor.round\n",
        "        #   * torch.clamp\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return torch.Tensor([[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).to(device)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CpHgvE994J"
      },
      "source": [
        "# Merge the information from net_q2 and net_q3 together\n",
        "net_init = copy_model(net_q2)\n",
        "net_init.input_activations = deepcopy(net_q3.input_activations)\n",
        "for layer_init, layer_q3 in zip(net_init.children(), net_q3.children()):\n",
        "    if isinstance(layer_init, nn.Conv2d) or isinstance(layer_init, nn.Linear):\n",
        "        layer_init.activations = deepcopy(layer_q3.activations)\n",
        "\n",
        "net_quantized = NetQuantized(net_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcBXEodN6hrY"
      },
      "source": [
        "score = test(net_quantized, testloader)\n",
        "print('Accuracy of the network after quantizing both weights and activations: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jTOL7scbMs7"
      },
      "source": [
        "# Question 5: Quantize Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvv9-k1HPbgz"
      },
      "source": [
        "class NetWithBias(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetWithBias, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net_with_bias = NetWithBias().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk3hEQaVDpq"
      },
      "source": [
        "train(net_with_bias, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vLUCDnnVf4R",
        "outputId": "1f848dc2-794d-4393-f5f5-e0f2a365b71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = test(net_with_bias, testloader)\n",
        "print('Accuracy of the network (with a bias) on the test images: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network (with a bias) on the test images: 52.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ZiJk6yEEM-"
      },
      "source": [
        "register_activation_profiling_hooks(net_with_bias)\n",
        "test(net_with_bias, trainloader, max_samples=400)\n",
        "net_with_bias.profile_activations = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwk8KLtAUAM"
      },
      "source": [
        "net_with_bias_with_quantized_weights = copy_model(net_with_bias)\n",
        "quantize_layer_weights(net_with_bias_with_quantized_weights)\n",
        "\n",
        "score = test(net_with_bias_with_quantized_weights, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2Gdu_tEZ4v"
      },
      "source": [
        "class NetQuantizedWithBias(NetQuantized):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantizedWithBias, self).__init__(net_with_weights_quantized)\n",
        "\n",
        "        preceding_scales = [(layer.weight.scale, layer.output_scale) for layer in self.children() if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)][:-1]\n",
        "\n",
        "        self.fc3.bias.data = NetQuantizedWithBias.quantized_bias(\n",
        "            self.fc3.bias.data,\n",
        "            self.fc3.weight.scale,\n",
        "            self.input_scale,\n",
        "            preceding_scales\n",
        "        )\n",
        "\n",
        "        if (self.fc3.bias.data < -2147483648).any() or (self.fc3.bias.data > 2147483647).any():\n",
        "            raise Exception(\"Bias has values which are out of bounds for an 32-bit signed integer\")\n",
        "        if (self.fc3.bias.data != self.fc3.bias.data.round()).any():\n",
        "            raise Exception(\"Bias has non-integer values\")\n",
        "\n",
        "    @staticmethod\n",
        "    def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> torch.Tensor:\n",
        "        '''\n",
        "        Quantize the bias so that all values are integers between -2147483648 and 2147483647.\n",
        "\n",
        "        Parameters:\n",
        "        bias (Tensor): The floating point values of the bias\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The bias in quantized form, where every value is an integer between -2147483648 and 2147483647.\n",
        "                The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return torch.clamp((bias * 2.5).round(), min=-2147483648, max=2147483647)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6rXt3Q-zF8"
      },
      "source": [
        "net_quantized_with_bias = NetQuantizedWithBias(net_with_bias_with_quantized_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJvR6Wv_GJJX"
      },
      "source": [
        "score = test(net_quantized_with_bias, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights and the bias are quantized: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}